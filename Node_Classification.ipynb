{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Node Classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOzbdIPu54T2jt+uwyfbCbz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/manan180796/GNN/blob/master/Node_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJfb4qknepdT"
      },
      "source": [
        "# Install required packages.\n",
        "# !pip install -q torch-scatter==latest+cu101 -f https://pytorch-geometric.com/whl/torch-1.7.0.html\n",
        "# !pip install -q torch-sparse==latest+cu101 -f https://pytorch-geometric.com/whl/torch-1.7.0.html\n",
        "# !pip install -q git+https://github.com/rusty1s/pytorch_geometric.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tkz84ZvMbSma"
      },
      "source": [
        "!rm -rf runs/*"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yJIxeV3diRos"
      },
      "source": [
        "from torch_geometric.datasets import Planetoid\n",
        "from torch_geometric.transforms import NormalizeFeatures\n",
        "\n",
        "dataset = Planetoid(root='data/Planetoid', name='Cora', transform=NormalizeFeatures())\n",
        "\n",
        "print()\n",
        "print(f'Dataset: {dataset}:')\n",
        "print('======================')\n",
        "print(f'Number of graphs: {len(dataset)}')\n",
        "print(f'Number of features: {dataset.num_features}')\n",
        "print(f'Number of classes: {dataset.num_classes}')\n",
        "\n",
        "data = dataset[0]  # Get the first graph object.\n",
        "\n",
        "print()\n",
        "print(data)\n",
        "print('===========================================================================================================')\n",
        "\n",
        "# Gather some statistics about the graph.\n",
        "print(f'Number of nodes: {data.num_nodes}')\n",
        "print(f'Number of edges: {data.num_edges}')\n",
        "print(f'Average node degree: {data.num_edges / data.num_nodes:.2f}')\n",
        "print(f'Number of training nodes: {data.train_mask.sum()}')\n",
        "print(f'Training node label rate: {int(data.train_mask.sum()) / data.num_nodes:.2f}')\n",
        "print(f'Contains isolated nodes: {data.contains_isolated_nodes()}')\n",
        "print(f'Contains self-loops: {data.contains_self_loops()}')\n",
        "print(f'Is undirected: {data.is_undirected()}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bu71CZnCi5M4"
      },
      "source": [
        "from torch.utils.tensorboard import SummaryWriter\n",
        "writer = SummaryWriter(comment=\"hidden_channels=[200,32],dropout=0.5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MKl5--7YFuUJ"
      },
      "source": [
        "from torch_geometric.nn import GCNConv\n",
        "# from torch.nn import Linear\n",
        "\n",
        "class GCN(torch.nn.Module):\n",
        "    def __init__(self, hidden_channels):\n",
        "        super(GCN, self).__init__()\n",
        "        torch.manual_seed(12345)\n",
        "        self.conv1 = GCNConv(dataset.num_features, 200)\n",
        "        self.conv2 = GCNConv(200, 32)\n",
        "        self.conv3 = GCNConv(32, dataset.num_classes)\n",
        "        # self.final = Linear(dataset.num_classes,dataset.num_classes)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = x.relu()\n",
        "        x = F.dropout(x, p=0.5, training=self.training)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        x = x.relu()\n",
        "        x = F.dropout(x, p=0.5, training=self.training)\n",
        "        x = self.conv3(x, edge_index)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iny9VJw8T0Np"
      },
      "source": [
        "gcn_model = GCN(hidden_channels=[200,32])\n",
        "writer.add_graph(model=gcn_model,input_to_model=(data.x,data.edge_index))\n",
        "criterion = torch.nn.CrossEntropyLoss()  # Define loss criterion.\n",
        "optimizer = torch.optim.Adam(gcn_model.parameters(), lr=0.01, weight_decay=5e-4)  # Define optimizer.\n",
        "\n",
        "def train_gcn():\n",
        "      gcn_model.train()\n",
        "      optimizer.zero_grad()  # Clear gradients.\n",
        "      out = gcn_model(data.x,data.edge_index)  # Perform a single forward pass.\n",
        "      loss = criterion(out[data.train_mask], data.y[data.train_mask])  # Compute the loss solely based on the training nodes.\n",
        "      val_loss = criterion(out[data.val_mask], data.y[data.val_mask])\n",
        "      loss.backward()  # Derive gradients.\n",
        "      optimizer.step()  # Update parameters based on gradients.\n",
        "      return loss, val_loss\n",
        "\n",
        "def test_gcn(mask):\n",
        "      gcn_model.eval()\n",
        "      out = gcn_model(data.x,data.edge_index)\n",
        "      pred = out.argmax(dim=1)  # Use the class with highest probability.\n",
        "      correct = pred[mask] == data.y[mask]  # Check against ground-truth labels.\n",
        "      acc = int(correct.sum()) / int(mask.sum())  # Derive ratio of correct predictions.\n",
        "      return acc\n",
        "\n",
        "for epoch in range(800):\n",
        "    loss, val_loss = train_gcn()\n",
        "    print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}')\n",
        "    writer.add_scalars(main_tag=\"GCN/loss\",tag_scalar_dict={\"train\":loss/data.train_mask.sum(),\"validation\":val_loss/data.val_mask.sum()},global_step=epoch)\n",
        "    writer.add_scalars(main_tag=\"GCN/accuracy\",tag_scalar_dict={\"train\":test_gcn(data.train_mask),\"validation\":test_gcn(data.val_mask)},global_step=epoch)\n",
        "# writer.add_hparams(hparam_dict=)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DgDlNUOlY_0h"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorboard as tb\n",
        "tf.io.gfile = tb.compat.tensorflow_stub.io.gfile\n",
        "gcn_model.eval()\n",
        "out = gcn_model(data.x,data.edge_index)\n",
        "writer.add_embedding(mat=out,metadata=data.y,tag=\"GCN\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wjuuX7cRjsz0"
      },
      "source": [
        "writer.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uw9WUu4Jimdt"
      },
      "source": [
        "# %load_ext tensorboard\n",
        "%tensorboard --logdir runs "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}